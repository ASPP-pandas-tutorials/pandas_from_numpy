{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010a6455",
   "metadata": {},
   "source": [
    "# Pandas DataFrames: Attributes and Methods\n",
    "\n",
    "<!---\n",
    "📝 NOTE-  Covered here:\n",
    "\n",
    "Columns in a dataframe  can be of different dtypes\n",
    "* Operations are on columns by default (describe, sum, min, max)\n",
    "* attributes of df (shape, dtypes columns, index)\n",
    "* methods of df (unique, describe, counts, value_counts, min, max, std, sort_values, sort_index)\n",
    "\n",
    "Structure of page:\n",
    "\n",
    "* show all relevant methods/attributes of numpy arrays\n",
    "\n",
    "* reinforce that \"Series = array + index + name\". Then show relevant methods/attributes of Series.\n",
    "\n",
    "* reinforce that \"DataFrame = dictionary-like collection of Series\". Then show all relevant methods/attributes of DataFrames.\n",
    "-->\n",
    "\n",
    "On the [previous](0_0_pandas_intro.Rmd) [pages](0_1_to_loc_or_iloc.Rmd) we have seen how Pandas Series are constructed by combining Numpy arrays (the `.values` attribute of a Series) with other attributes (a `.name` string and and array-like `.index`). We have then examined how Pandas Data Frames are built from a collection of Series, in a dictionary-like structure.\n",
    "\n",
    "This page will dive deeper into Data Frames. Once we have constructed our Data Frame, Pandas provides many useful methods for cleaning, aggregating, plotting and (subsequently) analysing our data.\n",
    "\n",
    "We will begin by showing that Pandas Series and Data Frames have many methods that parallel those of Numpy arrays, though the methods are adapted to work in the context of Pandas objects.\n",
    "\n",
    "## More Pandas from Numpy\n",
    "\n",
    "Let's examine some of the methods we can use on numpy arrays.\n",
    "\n",
    "Remember, a *method* is a function attached to an object. \n",
    "\n",
    "In this case, our object is a Numpy array (later it will be a Pandas Series or Data Frame).\n",
    "\n",
    "We'll build a Numpy array using the `np.array([])` constructor, containing our\n",
    "familiar three-letter country codes. As before, you can see the [datasets and\n",
    "licenses page](data/data_notes) for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0a7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Our own routine to giving hints to the exercises.\n",
    "from hint import hint_1, hint_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d47fa7",
   "metadata": {},
   "source": [
    "We build the constituent arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard three-letter code for each country\n",
    "country_codes_array = np.array(['AUS', 'BRA', 'CAN',\n",
    "                                'CHN', 'DEU', 'ESP',\n",
    "                                'FRA', 'GBR', 'IND',\n",
    "                                'ITA', 'JPN', 'KOR',\n",
    "                                'MEX', 'RUS', 'USA'])\n",
    "country_codes_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human Development Index Scores for each country\n",
    "hdis_array = np.array([0.896, 0.668, 0.89,\n",
    "                       0.586, 0.89,  0.828,\n",
    "                       0.844, 0.863, 0.49,\n",
    "                       0.842, 0.883, 0.824,\n",
    "                       0.709, 0.733, 0.894])\n",
    "hdis_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b01f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full names of each country.\n",
    "country_names_array = np.array(['Australia', 'Brazil', 'Canada',\n",
    "                                'China', 'Germany', 'Spain',\n",
    "                                'France', 'United Kingdom', 'India',\n",
    "                                'Italy', 'Japan', 'South Korea',\n",
    "                                'Mexico', 'Russia', 'United States'])\n",
    "country_names_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b90814",
   "metadata": {},
   "source": [
    "When dealing with any object in python, it can be useful to use the in-built python `dir()` function. This returns the *names* of every attribute and method that we can access/call from the object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f354069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all available attributes/methods\n",
    "dir(hdis_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475eb5df",
   "metadata": {},
   "source": [
    "For now we will ignore the elements in the printout that contain `__`.  These\n",
    "double underscores are called \"dunders\" (short for double underscores);\n",
    "attributes and methods starting and ending with `__` are often called *dunder\n",
    "attributes* and *dunder methods*.  Python uses the dunder naming scheme as\n",
    "a convention to indicate that these methods and attributes are part of the\n",
    "internal machinery of an object.\n",
    "\n",
    "Another Python naming convention uses an underscore `_` at the start of\n",
    "a method or attribute name to indicate that the method or attribute is\n",
    "*private* — that is, the attribute / method is for the object to use, but for\n",
    "us — the user of the object — to avoid.\n",
    "\n",
    "Ignoring the dunder attributes and methods, and those beginning with underscores, we can see a large number of\n",
    "attributes and methods that we can access from this or any other Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b4fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes and methods not starting with `_` (or `__`):\n",
    "[k for k in dir(hdis_array) if not k.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9dbf6",
   "metadata": {},
   "source": [
    "One of these `array` attributes is `shape`. We often want to know the `shape` of our data, as it tells us the number of elements along each dimension (axis) of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9fc1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape\n",
    "hdis_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3843cf84",
   "metadata": {},
   "source": [
    "We can read this output as \"15 elements in a single dimension\". By contrast, let's look at an array with more than one dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a477891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays with more dimensions\n",
    "zeros_array = np.zeros([2, 2])\n",
    "zeros_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d598350a",
   "metadata": {},
   "source": [
    "This 2D array has the following shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays with more dimensions\n",
    "zeros_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4c64f2",
   "metadata": {},
   "source": [
    "We an read this as \"2 rows and 2 columns\" (which equates to 4 elements), or \"two elements along the first dimension, two elements along the second\".\n",
    "\n",
    "If we want to count the number of individual elements in an array (across all dimensions) we can use the `.size` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many elements in the (15, ) `hdi` array?\n",
    "hdis_array.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1953847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many elements in the (2, 2) `zeros_array`?\n",
    "zeros_array.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13b76e",
   "metadata": {},
   "source": [
    "`len()` as applied to Numpy arrays gives us the number of elements of the *first dimension* (axis) only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zeros_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf0fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hdis_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54224350",
   "metadata": {},
   "source": [
    "**Start of note**\n",
    "\n",
    "**How does `len()` work?**\n",
    "\n",
    "Calling the standard Python function `len()` on an object `obj` causes Python to call the `__len__()` method of the object.  Therefore, the result of `len(obj)` is the same as that for `obj.__len__()`. \n",
    "\n",
    "Each object type can define what `len(obj)` means.  For Numpy arrays `arr.__len__()` gives you the equivalent of `arr.shape[0]`. \n",
    "\n",
    "Later we will see that Data Frames have their own implementation of `__len__`.\n",
    "\n",
    "**End of note**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab411ba8",
   "metadata": {},
   "source": [
    "We also often want to know the type of data in our array, as it will affect the analyses we can perform. Are we dealing with numbers or text, for instance? \n",
    "\n",
    "To access this information, we can view the `dtype` attribute. \n",
    "\n",
    "Let's look at the `dtype` for the `country_codes` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dtype\n",
    "country_codes_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812c661",
   "metadata": {},
   "source": [
    "The `dtype` attribute here is just telling us that this is string data. For an explanation of the meaning, see the image below.\n",
    "\n",
    "![](images/numpy_string_dtypes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb45ec",
   "metadata": {},
   "source": [
    "Let's look at the `dtype` of the `hdis_array`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dtype (again)\n",
    "hdis_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b48bf",
   "metadata": {},
   "source": [
    "For this array, the `dtype` tells us that we are dealing with numerical data - specifically float data represented with 64 bits of memory per element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf28172f",
   "metadata": {},
   "source": [
    "### Statistical Attributes of Numpy arrays\n",
    "\n",
    "Numpy also provides a variety of what we can call \"statistical attributes\" which tell us statistics about the data inside the array.\n",
    "\n",
    "**Start of note**\n",
    "\n",
    "**What is a statistic**\n",
    "\n",
    "A statistic is some number or sequence of numbers that summarizes a distribution of values.  For example, the mean or average is a measure of the center of the distribution.  Similarly the min and max are the values on the extreme left and extreme right of a distribution.\n",
    "\n",
    "**End of note**\n",
    "\n",
    "As with the methods we looked at in the previous section, Pandas has its own versions of many of these methods, as we will see later in the page.\n",
    "\n",
    "Let's again look at the `hdis_array`, which contains the HDI score of each country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741edb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdis_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925fb06",
   "metadata": {},
   "source": [
    "There are a variety of useful statistical methods for arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum value in entire array.\n",
    "hdis_array.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum value in entire array.\n",
    "hdis_array.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff40d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of all values in array.\n",
    "hdis_array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation.\n",
    "hdis_array.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb9eb1",
   "metadata": {},
   "source": [
    "## Pandas Series attributes and methods\n",
    "\n",
    "Remember our answer to \"What is a Series\"?:\n",
    "\n",
    "> A *Series* is the association of:\n",
    ">\n",
    "> * An array of values (`.values`)\n",
    "> * A sequence of labels for each value (`.index`)\n",
    "> * A name (which can be `None`).\n",
    "\n",
    "Because Series have arrays as their underlying model for storing values, it is\n",
    "not surprising that we can use many of the same methods we have just seen for\n",
    "Numpy arrays on Pandas Series.\n",
    "\n",
    "Let's make a series from the HDI scores, called `hdi_series`. We do this using the now familiar `pd.Series()` constructor. Again, we will use the `country_codes` array as an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e7f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show again from Series, then show for df below\n",
    "hdi_series =  pd.Series(hdis_array,\n",
    "                        index=country_codes_array)\n",
    "\n",
    "hdi_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367edd2",
   "metadata": {},
   "source": [
    "As we know, we can view the `index`, `name` and `values` attributes of the Series using the familiar accessors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `index` component of the Series\n",
    "hdi_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `name` component (currently is None)\n",
    "hdi_series.name is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numpy array (aka `.values`) component of the Series\n",
    "hdi_series.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d838dcf",
   "metadata": {},
   "source": [
    "Let's verify that we can use methods that parallel the Numpy methods we saw above. Predictably, these methods operate on the Numpy array component of the series (e.g. the `.values` attribute). \n",
    "\n",
    "First, let's look at the `shape`, `size` and `dtype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07216f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the `shape` of the `hdi_series`\n",
    "hdi_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99749268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the `size` of the `hdi_series`\n",
    "hdi_series.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the `dtype` of the `hdi_series`\n",
    "hdi_series.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150da08",
   "metadata": {},
   "source": [
    "Because a Series is a Numpy array (of `.values`) plus some additional attributes/methods, these methods function on the Series in a very similar manner to their equivalents on Numpy arrays.\n",
    "\n",
    "This also applies to statistical methods. Let's get the `.min()` and `.max()` values from the `hdi_series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c47c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min\n",
    "hdi_series.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae0c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max\n",
    "hdi_series.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50837b",
   "metadata": {},
   "source": [
    "These operations return the same values as when we call the method directly on the `hdis_array` (unsurprising, as each object contains the same data)!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the `max()` value from the `hdis_array`, for comparison\n",
    "hdis_array.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f11e6",
   "metadata": {},
   "source": [
    "Ok, so these methods are available with names that are familiar from Numpy.\n",
    "However, Pandas also introduces some additional methods.  You may want to\n",
    "compare the output of `dir()` for the `hdis_array` vs the `hdi_series` to see\n",
    "the overlap/differences - as the printout is messy, we will not show it again\n",
    "here.\n",
    "\n",
    "One very useful Series method is `.describe()`. This will give us a variety of\n",
    "statistics about the data in the `.values` array of the Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176cbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `.describe()` on the `hdi_series`\n",
    "hdi_series.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1402ae",
   "metadata": {},
   "source": [
    "Neat, an easy summary of the number of observations, the mean, the standard deviation around the mean, and then the range/interquartile range.\n",
    "\n",
    "Conversely, the `.value_counts()` method will count the occurrence of each *unique* value in the Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2171541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `value_counts()` method\n",
    "hdi_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7f527",
   "metadata": {},
   "source": [
    "These methods can also be applied to arrays containing categorical/string\n",
    "data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba327fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a Series containing categorical data\n",
    "country_names_series = pd.Series(country_names_array,\n",
    "                                 index=country_codes_array)\n",
    "\n",
    "country_names_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97603b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .describe()\n",
    "country_names_series.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c6760",
   "metadata": {},
   "source": [
    "Helpfully, Pandas has adjusted the `.describe()` summary in light of the\n",
    "`values` array of the `country_names_series` containing categorical/string\n",
    "data.\n",
    "\n",
    "We now see summaries of the number of values, number of unique values etc,\n",
    "rather than numerical statistics like the mean and standard deviation.\n",
    "\n",
    "The `.value_counts()` method behaves the same as with numerical data, as both\n",
    "numbers and strings can be unique in an array.  For our case, the output isn't very interesting, as all the country names are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b49d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_names_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680df7bd",
   "metadata": {},
   "source": [
    "If we want to see the *unique* values only, regardless of the number of times each value occurs, we can use the `.unique()` method.  This gives us a sorted array of the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec365039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the unique values in the Series\n",
    "hdi_series.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the unique values in the Series\n",
    "country_names_series.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But of course, all the country names are unique, and they \n",
    "# are already sorted alphabetically, so the \n",
    "# above is the same, in our case, as:\n",
    "country_names_series.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e9a59",
   "metadata": {},
   "source": [
    "## Pandas Data Frame attributes\n",
    "\n",
    "Now, remember again our other maxim that *A *Data Frame* is a dictionary-like collection of Series.*\n",
    "\n",
    "Because of this, we can use all the methods we have seen so far on any Data Frame column. Each column is a Series, and therefore contains a Numpy array as its `.values` attribute.\n",
    "\n",
    "However, Data Frames have some (useful!) extra methods (including statistical methods) not available for Series.\n",
    "\n",
    "First, let's import the [HDI/fertility rate data](https://ourworldindata.org/grapher/children-per-woman-vs-human-development-index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dataset\n",
    "df = pd.read_csv(\"data/year_2000_hdi_fert.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f1dcf9",
   "metadata": {},
   "source": [
    "We can use `dir()` on this Data Frame, to view all of the available\n",
    "attributes and methods (that don't begin with `_`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all available operations on the dataframe\n",
    "[k for k in dir(df) if not k.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ef1be",
   "metadata": {},
   "source": [
    "If you peruse the list you'll notice that some of the methods have the sames as methods that apply to both Numpy arrays and Series. For instance, we can retrieve the `.shape` of the entire Data Frame.  This gives us the number of rows and the number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape attribute (n_rows, n_columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3415dc25",
   "metadata": {},
   "source": [
    "`len(df)` (therefore, `df.__len__()`) gives the number of rows.  This corresponds the Numpy behavior of giving the number of elements on the first dimension of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of Data Frame is number of rows.\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f7e467",
   "metadata": {},
   "source": [
    "We can also pull out an individual Series/column and view the `.shape` of that specific Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c286da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the `shape` of a specific column\n",
    "df['Fertility Rate'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0745f6e",
   "metadata": {},
   "source": [
    "When accessed for the entire Data Frame, the `size` attribute works in the same way as we have seen for Numpy arrays and Pandas Series e.g. it will tell us the total number of *elements* in the entire Data Frame (e.g. the number of elements in the rows multiplied by the number of elements in the columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the `size` of the Data Frame\n",
    "df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59afe81b",
   "metadata": {},
   "source": [
    "**Start of exercise**\n",
    "\n",
    "Your job here is to make a new Series which summarises aspects of the `df` Data Frame. In the `.values` array, your Series should contain the values of the `.shape` and `.size` attributes of `df`. It should also contain the `dtype` of the `index` of `df` (therefore, telling your user whether the `index` contains numeric labels, `str` labels, or something else). See if you can figure out how to get Pandas to report this via indexing (e.g. rather than copy pasting the information from the output of `df.index`).\n",
    "\n",
    "The `index` of your Series should clearly state what each `value` is. E.g. the strings `shape`, `size`, `index_dtype` should be the `index` labels in your Series. \n",
    "\n",
    "The `name` attribute of your Series should be`df_attributes`.\n",
    "\n",
    "When displayed, your Series should look like this:\n",
    "\n",
    "```\n",
    "shape          (15, 4)\n",
    "size                60\n",
    "index_dtype     object\n",
    "Name: df_attributes, dtype: object\n",
    "```\n",
    "\n",
    "Try to create this Series in as few lines of code as possible. \n",
    "\n",
    "You may run into an error with the `shape` attribute. Try running `hint_1()` for a hint on how to solve this.\n",
    "\n",
    "You can also run `hint_2()` to get a hint on how to get Pandas to report the `dtype` of the `index`.\n",
    "\n",
    "**Try to use the hints as a last resort, however...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282bad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eeb0f8",
   "metadata": {},
   "source": [
    "**End of exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1716c13",
   "metadata": {},
   "source": [
    "**See the [corresponding page](/pandas_from_numpy/0_2_pandas_dataframes_attributes_methods.html) for solution**\n",
    "\n",
    "Once we've done these preliminary inspections and we know how many observations we have, in any data analysis context, we will always want to know what variables we have in the Data Frame columns, and (again) what type of data is in each.\n",
    "\n",
    "The `.columns` attribute will tell us the name (label) for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e1a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb29f81",
   "metadata": {},
   "source": [
    "...and we can use the `.dtypes` attribute to inspect the type of data in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09296bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dtype in each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556fc9e1",
   "metadata": {},
   "source": [
    "The `object` data type means that the column contains either mixed data or string data (in this case string data). The numeric data in this Data Frame is represented as a 64-bit float (`float64`).\n",
    "\n",
    "Now we know how much data we have, and what type of data it is. Currently, if\n",
    "we want to access a specific row of the Data Frame (remember, each row here is\n",
    "one country), we will have to index either by position, or by using the labels from the default `RangeIndex`. We did not\n",
    "specify an index when we loaded in the Data Frame, so, as we learned\n",
    "previously, Pandas will automatically supply one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the index (representing the integers 0 through 14)\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fc1c6",
   "metadata": {},
   "source": [
    "We have [already discussed](0_1_to_loc_or_iloc.Rmd) the downsides of using the default (integer) index. As we have seen before, we can use the `.set_index()` method to choose a column containing values which we will use as index labels. We have come across Data Frame methods previously (`.sort_values()`) and will look at more in the next section. For now, just remember that *methods* differ from data *attributes* in that they are a *function attached to an object* rather than just a value attached to an object. Methods often do something to or with the data rather than just report a value or set of values, like an attribute does.\n",
    "\n",
    "Let's set the `Code` column (containing the three-letter country codes) to be our index labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115d9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index as country name\n",
    "df = df.set_index(\"Code\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276ea7f",
   "metadata": {},
   "source": [
    "As expected, when we now view the `index` attribute, we see that the country codes are the values that populate the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afef79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that the index is now country names\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651e846",
   "metadata": {},
   "source": [
    "...and we can use the now familiar (and less error-prone) label-based indexing with strings to retrieve specific rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703438d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember what having the codes in the index lets us do\n",
    "df.loc[['USA', 'ITA']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100d8df",
   "metadata": {},
   "source": [
    "## Pandas Data Frame methods\n",
    "\n",
    "The `.sort_values()` method we used on the [previous page](0_1_to_loc_or_iloc.Rmd) and the `set_index()` method we just used in the last section are just some of the many methods attached to Pandas Data Frames. We saw that many Numpy array methods have parallel versions that apply to Pandas Series and this principle also applies to Data Frames, built as they are from Pandas Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065080a5",
   "metadata": {},
   "source": [
    "Many Data Frame methods will report information from the Data Frame *as a whole*, rather than just for a given column/Series.\n",
    "\n",
    "For instance, remember the `.describe()` method for a Series.  Here we pull out a column from the Data Frame with direct indexing, and then call `.describe()` on that Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90fb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the HDI column out of the Data Frame with direct indexing.\n",
    "hdi_from_df = df['Human Development Index']\n",
    "# The result is a Series, on which we can call the Series\n",
    "# `.describe()` method.\n",
    "hdi_from_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc1fb2",
   "metadata": {},
   "source": [
    "We can also call the `.describe()` method on the whole Data Frame. The same useful statistical summary is shown for every column when we use the method on the whole Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe numerical variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3bde72",
   "metadata": {},
   "source": [
    "We can also use direct indexing to `describe` a specific subset of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3fa0cb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# For categorical variables\n",
    "# Define columns we want to select.\n",
    "cols = ['Fertility Rate', 'Human Development Index']\n",
    "# Select columns by direct indexing, then describe.\n",
    "df[cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076a9a4",
   "metadata": {},
   "source": [
    "**Start of exercise**\n",
    "\n",
    "Write code you need to create a Series that contains the just the means of the `Human Development Index`, `Fertility Rate` and `Population` variables. For good measure, let's also require that the `name` attribute is set to `mean`. The output should look like this:\n",
    "\n",
    "```\n",
    "Human Development Index      0.789333\n",
    "Fertility Rate               1.773867\n",
    "Population                 236.719867\n",
    "Name: mean, dtype: float64\n",
    "```\n",
    "\n",
    "Try to do this in as few lines of code as possible, using the methods shown on this page..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d67806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d486dcd",
   "metadata": {},
   "source": [
    "**End of exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdbccf",
   "metadata": {},
   "source": [
    "**See the [corresponding page](/pandas_from_numpy/0_2_pandas_dataframes_attributes_methods.html) for solution**\n",
    "\n",
    "Because each Data Frame column is just a Pandas Series, all of the Series methods we saw above can be used on individual Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of Series extracted from a Data Frame.\n",
    "df['Fertility Rate'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dddcd4",
   "metadata": {},
   "source": [
    "By contrast, other methods, like `.sort_values()` take a column name as an argument, but have effects on the entire Data Frame.\n",
    "\n",
    "For instance, if we want to sort *rows of the whole Data Frame* by `Human Development Index` scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ed6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values by HDI, lowest value first (sort ascending).\n",
    "df_by_hdi = df.sort_values('Human Development Index')\n",
    "df_by_hdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53957b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values by HDI, highest value first (sort descending).\n",
    "df_by_hdi_reversed = df.sort_values('Human Development Index',\n",
    "                                    ascending=False)\n",
    "df_by_hdi_reversed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8223bc6",
   "metadata": {},
   "source": [
    "We can also sort the Data Frame rows by the values in the index, using `.sort_index()`.  By default this sorts the Index values from lowest to highest.  Because the Index in our case has `str` values, this sorts the Index in alphabetical order, so `df.sort_index()` will arrange the rows of the Data Frame in alphabetical order according to the Index values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc91f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort index (in alphabetical order)\n",
    "df_by_hdi_reversed.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort index (reverse alphabetical order)\n",
    "df_rev_ind = df_by_hdi_reversed.sort_index(ascending=False)\n",
    "df_rev_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896234fe",
   "metadata": {},
   "source": [
    "Another useful method that can be powerful in tandem with label-based indexing, is `.drop()`. This lets us specify rows, using index labels, that we want to remove from the Data Frame. For instance, if we want to remove the data for Australia we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fac0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'USA' row\n",
    "df_rev_ind.drop(index='USA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b831e",
   "metadata": {},
   "source": [
    "If you compare this to the output from the last cell you will see that, as if by magic, the row for `USA` has disappeared.\n",
    "\n",
    "In addition to removing data from the Dataframe, we will also often want to replace data. Maybe we want to recode categorical data with better labels, create custom dummy/indicator variables, or correct errors etc.\n",
    "\n",
    "We can replace values using the descriptively named `.replace()` method. Lets say we want to use the abbreviation `UK` instead of `United Kingdom` in the `Country Name` column. We just give `.replace()` the value we want to replace, followed by the value we want to replace it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e3dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `.replace()` method applied to a Series (in a Data Frame).\n",
    "df['Country Name'].replace(\"United Kingdom\", \"UK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565dde60",
   "metadata": {},
   "source": [
    "Sure enough, `United Kingdom` has been replaced with `UK` in the Series in the output of the cell above. We can also do this with [collections of values](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html) (e.g. using a `dict` or `list` etc) rather than just single values, should we feel moved to do so.\n",
    "\n",
    "By default, `.replace()` only replaces values that are equal to the first (target) argument to `.replace`.\n",
    "\n",
    "For instance, we might expect the following code to replace `United` in both `United Kingdom` and `United States`, but we would be wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59834134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not what we want.\n",
    "df['Country Name'].replace(\"United\", \"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e6c46",
   "metadata": {},
   "source": [
    "This did not work because `.replace()` is searching for an element of the Series which *equals* `United`, not that *contains* `United`. (There is an alternative string-specifc `.replace()` method, which behaves differently as we will see on a [later page](0_6_more_pandas_methods_strings)).\n",
    "\n",
    "We can achieve the desired result using the `regex` (standing for \"regular expression\") argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28597d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowing replace on a partial match.\n",
    "df['Country Name'].replace(\"United\", \"Unknown\",\n",
    "                           regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0408c3",
   "metadata": {},
   "source": [
    "With `regex=True`, the `.replace()` method has searched for matches *within* other strings. So, `United` has been replaced in both `United Kingdom` and `United States`, despite not matching either string in full.\n",
    "\n",
    "The `.replace` method can also be used for Series with numeric `dtype`s. For instance, some particularly patriotic data analyst might want to do the following replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Replace method, with numeric data.\n",
    "df['Human Development Index'].replace(0.894, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a568496",
   "metadata": {},
   "source": [
    "### Methods for getting subsets of data from a Data Frame\n",
    "\n",
    "Another common operation we may want to perform is to view only the start (e.g. the `.head`) or the end (e.g. the `.tail`) of a Data Frame. For instance, if the rows are organized by time, amongst many other reasons.\n",
    "\n",
    "We could just use `.iloc` position-based indexing to do this. For example, to view the first three rows of the Data Frame we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first three rows of the Data Frame, using `.iloc`\n",
    "df.iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc2a7b",
   "metadata": {},
   "source": [
    "Or, alternatively, to view the last three rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75febd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the last three rows of the Data Frame, using `.iloc`\n",
    "df.iloc[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d794f",
   "metadata": {},
   "source": [
    "However, the kind folks at Pandas, because these operations are so common, have provided us the `.head()` and `.tail()` methods to do the same thing, with less typing and better readability.\n",
    "\n",
    "`.head()` without arguments gives us the first five rows, equivalent to `.iloc[5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade49695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default .head() gives first five rows.\n",
    "# Equivalent to `df.iloc[:5]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72867fb",
   "metadata": {},
   "source": [
    "We can pass an integer to the `.head()` method to specify the number of rows from the start of the Data Frame which we want to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of rows to .head().\n",
    "# Equivalent to `df.iloc[:3]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d08e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first three rows of the Data Frame, using `.head()`\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce542765",
   "metadata": {},
   "source": [
    "We can also do the same thing at the other end of the Data Frame, using the `.tail()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, `.tail()` gives the last five rows of the Data Frame.\n",
    "# Equivalent to `df.iloc[-5:]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2520d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of rows counting from the last.\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23924893",
   "metadata": {},
   "source": [
    "In addition to retrieving rows from the extremes of the Data Frame, we may also, for many different purposes, want to retrieve a *random* set of rows.\n",
    "\n",
    "We can do this using the `.sample()` method. The syntax here is just the same as for `.head()` and `.tail()`, only now we are specifying the *number of random rows* we want to grab from the Data Frame.\n",
    "\n",
    "For instance, if let's say we want to get three random rows, without replacement (so that we can't get the same row twice):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d5d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab three rows at random using `.sample()`\n",
    "df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6fc126",
   "metadata": {},
   "source": [
    "Even using the small dataset we have here, the overwhelming probability is that we will get a different selection of rows each time we run this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab three rows at random AGAIN using `.sample()`\n",
    "df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de3f37",
   "metadata": {},
   "source": [
    "If you are running this tutorial interactively, re-run the cell above a few times to see randomness in action..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff9e26",
   "metadata": {},
   "source": [
    "Check the documentation for `.sample` by uncommenting the cell below, and running the cell (e.g. with Shift-Return):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aaca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show documentation with (uncomment below and run):\n",
    "df.sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec0567",
   "metadata": {},
   "source": [
    "Notice that by default the sampling is *without replacement*, so once a row has been pulled into the output sample, it cannot be selected again for the remaining values in the sample.  When we deal out hands of cards from a standard 52-card deck., we are sampling from the pack without replacement, because any one card cannot be dealt more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first five rows.\n",
    "first_five = df.head()\n",
    "# Sample four values without replacement (the default).\n",
    "first_five.sample(n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0ce64",
   "metadata": {},
   "source": [
    "Notice that no row appears twice in the sample.  Notice too that if we pass in an `n` of more than the number of rows, resampling without replacement has to fail, because it will run out of rows to sample from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a7029",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Trying to take a without-replacement sample that is too large.\n",
    "first_five.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88792885",
   "metadata": {},
   "source": [
    "Conversely, if we specify with-replacement sampling, we can ask for as many values as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling 10 values from original 5, *with replacement*.\n",
    "first_five.sample(n=10, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7be1ad",
   "metadata": {},
   "source": [
    "We have so far specified the size of our sample with `n` — the number of rows\n",
    "in the sample — but we can also specify the size as a fraction of the whole\n",
    "Data Frame.  To get a sample that is half the size the original Data Frame\n",
    "(`np.round(15 / 2) == 8`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take sample half the size of the original.\n",
    "df.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f900160",
   "metadata": {},
   "source": [
    "**Start of exercise**\n",
    "\n",
    "There are functions within Numpy (as well as other libraries) that shuffle/permute/randomize data within an array (or an arraylike object, such as a list).\n",
    "\n",
    "Let's say we want to shuffle the *rows* in our Data Frame. We can do this with the `permutation()` function from the `numpy.random` submodule, but the output is very ugly. This operation brutally removes the nice Data Frame graphics (at least when run in a Jupyter notebook), and puts the rows of the Data Frame into a Numpy array, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c038c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effective but ugly\n",
    "np.random.permutation(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb91880",
   "metadata": {},
   "source": [
    "Can you think of a way to perform this operation using only the Pandas methods we have seen so far on this page? In the cell below, you should write code which will:\n",
    "\n",
    "- randomize the order of the *rows* in the Data Frame. The data in each row should be the same as before shuffling (e.g. the data for Russia should still be the data for Russia etc.)\n",
    "\n",
    "- ensure that no rows are removed or duplicated, just shuffled\n",
    "\n",
    "Try to find the solution in the cell below. Use as few lines of code as possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47df7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba3247",
   "metadata": {},
   "source": [
    "**End of exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac55750f",
   "metadata": {},
   "source": [
    "**See the [corresponding page](/pandas_from_numpy/0_2_pandas_dataframes_attributes_methods.html) for solution**\n",
    "\n",
    "We mentioned above that the default behaviour of the `.sample()` method is to sample *without replacement*. We also mentioned that you can use the `replace=` argument to sample *with* replacement.\n",
    "\n",
    "To use a classic \"drawing marbles from a bag\" analogy, this means that when we randomly select a marble, we place it *back* in the bag (after recording it's identity/colour etc) before we randomly draw the next marble. This means the same marble can appear twice in the final sample. \n",
    "\n",
    "As mentioned above, if we draw a sample of rows *with replacement* from our Data Frame, then individual rows can appear more than once in the resultant sample. If we draw a sample with replacement which is *larger* than the original data, it will certainly contain duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sample with replacement\n",
    "df.sample(len(df) + 10, \n",
    "          replace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf7efb",
   "metadata": {},
   "source": [
    "Quickly scan the `index` for duplicates, to see that it contains duplicates (as it must, in order to generate a sample of this size).\n",
    "\n",
    "Your task is the following:\n",
    "\n",
    "- take a random sample *with replacement* of all the rows in the Data Frame (e.g. your sample should have the *same number of rows* as the original Data Frame)\n",
    "\n",
    "- use an appropriate method to calculate the means of `Human Development Index`, `Fertility Rate` and `Population`, from your random sample\n",
    "\n",
    "- using Pandas methods and indexing operations, calculate the *difference* between the means of `Human Development Index`, `Fertility Rate` and `Population` in your sample vs the means for the same variables in the original data\n",
    "\n",
    "- store your result in a Pandas Series (note: depending what methods you use, your result may automatically be stored in a Pandas Series)\n",
    "\n",
    "The result should look something like this (though your differences will differ from the ones shown below, because of the randomness inherent in your sampling):\n",
    "\n",
    "```\n",
    "Human Development Index      0.074467\n",
    "Fertility Rate              -0.182600\n",
    "Population                -210.516580\n",
    "Name: mean, dtype: float64\n",
    "```\n",
    "\n",
    "Try to do this in as few lines of code as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88abf2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91818b43",
   "metadata": {},
   "source": [
    "**End of exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a0cafb",
   "metadata": {},
   "source": [
    "**See the [corresponding page](/pandas_from_numpy/0_2_pandas_dataframes_attributes_methods.html) for solution**\n",
    "\n",
    "## Plotting Methods\n",
    "\n",
    "The Data Frame plotting *methods* that we have seen on the previous pages actually also apply to Series.\n",
    "\n",
    "When working with a Series, it makes most sense most of the time to use the `kind = 'hist'` argument to inspect the distribution of the data in that Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdi_series.plot(kind='hist');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f114de84",
   "metadata": {},
   "source": [
    "Other kinds of plot require data specified both for the x- and y- axes, so can only be used with Data Frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf893188",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# A ValueError from trying to scatter plot a Series\n",
    "hdi_series.plot(kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bf9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a scatter plot on a Data Frame, specifying x- and y- axes.\n",
    "df.plot(x='Human Development Index',\n",
    "        y='Fertility Rate',\n",
    "        kind='scatter');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd6a9a3",
   "metadata": {},
   "source": [
    "## A note on numerical operations\n",
    "\n",
    "Any numerical operations performed on the Data Frame *as a whole* will be default be performed on the `values` in the Series that make up each column.\n",
    "\n",
    "So, if we want to do something like multiplying the entire Data Frame by a single number, this operation will be performed separately on each element of each Series in the Data Frame.\n",
    "\n",
    "This might make sense for some Data Frames, but in our case, we have string data in one column, so applying the multiplication to values in the `str` Series will give us results we probably didn't want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This probably won't make sense in our case.\n",
    "df * 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f5b49c",
   "metadata": {},
   "source": [
    "More sensibly, we will most likely want to perform numerical operations on specific columns. We may want to *standardize* the values relative to a mean of 0 and standard deviation of 1, for instance.\n",
    "\n",
    "**Start of note**\n",
    "\n",
    "**Standard scores**\n",
    "\n",
    "If we have a sequence of values, we can calculate corresponding scores for that sequence by first subtracting the mean of the sequence, and second, dividing the result by the standard deviation of the original sequence.\n",
    "\n",
    "The result is the [standard score](https://en.wikipedia.org/wiki/Standard_score) of each element in the sequence.\n",
    "\n",
    "The process of calculating standard scores can be called *standardization*.  Standard scores are sometimes called *z-scores*.\n",
    "\n",
    "**End of note**\n",
    "\n",
    "Pandas methods can be used to perform this computation, and again, the operation will be performed on each element in the `values` array of the specific Series/column that we grab.\n",
    "\n",
    "For instance, to subtract the mean value from every element in the `.values` array we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the mean from every element in the Series\n",
    "df['Population'] - df['Population'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a33779",
   "metadata": {},
   "source": [
    "We can perform the full z-score standardization using the code in the cell below. Note that `df['Population'].mean()` and `df['Population'].std()` both return single values. Each of these values is used in the same way on every element in the `Population` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the `Population` scores\n",
    "df['Population_z'] = ((df['Population'] - df['Population'].mean())\n",
    "                      / df['Population'].std())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaef72d",
   "metadata": {},
   "source": [
    "Because this feature (numerical operations performed on each element) is shared across all Pandas Series, and we are using Pandas methods, we can write a function which will compute the z-scores for any column containing numerical data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate standard scores for a numeric Series.\n",
    "def get_standard(in_series):\n",
    "    \"\"\" Returns Series with standard score of each element of `in_series`.\n",
    "    \"\"\"\n",
    "    # Formula for standard score.\n",
    "    return (in_series - in_series.mean()) / in_series.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test our function\n",
    "get_standard(df['Human Development Index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb298ba",
   "metadata": {},
   "source": [
    "Again, each numerical operation that the function performs has been performed on every element of the `.values` array of the Data Frame column `Human Development Index`.\n",
    "\n",
    "Let's add these new standardized data to the Data Frame, and plot them using the now familiar `.plot()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add standard scores for HDI\n",
    "df['HDI_z'] = get_standard(df['Human Development Index'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe970cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the standardized variables.\n",
    "# Notice both range from negative to positive.\n",
    "df.plot(kind='scatter',\n",
    "        x='Population_z',\n",
    "        y='HDI_z');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140255f",
   "metadata": {},
   "source": [
    "We can see from this procedure that we have two bivariate outliers, with respect to `Population` and `HDI`, at the bottom right of the scatter plot.\n",
    "\n",
    "This dataset is small enough that we can see that these values correspond to India and China..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the `Population_z` column to identify the outliers\n",
    "df['Population_z'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc426e4",
   "metadata": {},
   "source": [
    "... but for a larger dataset we could find them using [Boolean filtering ](0_5_filtering_data_with_pandas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef91c3e9",
   "metadata": {},
   "source": [
    "**Start of exercise**\n",
    "\n",
    "If you use `.plot(kind=\"bar\")` you will generate a bar plot (that is, a chart with bars representing counts for different categories).\n",
    "\n",
    "Your task is to use indexing methods of your choice, restricting yourself to the Pandas methods shown on this page, to create a bar plot which has:\n",
    "\n",
    "* the name of each country on the x-axis\n",
    "\n",
    "...and...\n",
    "\n",
    "* bars which show the population of the country on the y-axis. The bars should be ordered from highest population (left hand side of the graph) to lowest population (right hand side of the graph).\n",
    "\n",
    "*Unless you enjoy cheating, do not use other plotting libraries!*. Your final result should look like this:\n",
    "\n",
    "![](images/bar_example.png)\n",
    "\n",
    "As ever, use as few lines as you can, while but keep your code readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059599b",
   "metadata": {},
   "source": [
    "**End of exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200953c",
   "metadata": {},
   "source": [
    "**See the [corresponding page](/pandas_from_numpy/0_2_pandas_dataframes_attributes_methods.html) for solution**\n",
    "\n",
    "## Summary\n",
    "\n",
    "On this page we have further explored the idea that Pandas Data Frames, Pandas\n",
    "Series and Numpy arrays have a nested structure.\n",
    "\n",
    "Data Frames are *dictionary-like collections of Series*. Series are a combination of a Numpy array (`.values`) with other attributes (`name` and `index`). As a result, many methods we can use on a Series are similar to those available from Numpy arrays, and many Data Frame methods likewise parallel those from the Pandas Series that constitute the Data Frame."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
