{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99489e7b",
   "metadata": {},
   "source": [
    "# Dealing with NaNs\n",
    "\n",
    "<!---\n",
    "📝 NOTE:\n",
    "Covered on this page/structure of this page:\n",
    "\n",
    "* Make an array and series containing NaNs and show how pandas and numpy treat them differently\n",
    "\n",
    "* Populating the region column? E.g. replacing the missing data?\n",
    "\n",
    "``\n",
    "# drop NaNs gives the same mean\n",
    "df['Fertility Rate'].loc['ZWE'].dropna().mean()\n",
    "``\n",
    "\n",
    "* NaNs are interpreted as missing data and ignored in most operations\n",
    "* Pandas uses NaN as a flag, not as an indication of a failed floating point\n",
    "  operation\n",
    "* Numpy does not have a concept of a missing value, NaNs propagate.\n",
    "* In Pandas NaN is an indication of missing data - Pandas will by default\n",
    "  drop nans from most operations).s\n",
    "-->\n",
    "\n",
    "[NaN](https://en.wikipedia.org/wiki/IEEE_754) is short for Not-a-Number.\n",
    "\n",
    "This page will compare how NaN values differ between Numpy and Pandas.\n",
    "\n",
    "You are probably aware that Numpy will produce NaNs from invalid floating\n",
    "point operations, such as dividing 0 by 0. In Pandas, NaNs are more commonly\n",
    "a flag to indicate the absence of data, for floating point and other data\n",
    "types.\n",
    "\n",
    "We will also look at how to handle NaNs safely in Pandas.\n",
    "\n",
    "First, let's remind ourselves how NaNs work in Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b217c20",
   "metadata": {},
   "source": [
    "## NaNs in Numpy\n",
    "\n",
    "As mentioned above, NaNs in Numpy result from invalid floating point\n",
    "operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65cb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# NaN results from a Numpy operation dividing 0 by 0\n",
    "a_nan = np.array(0) / np.array(0)\n",
    "a_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b334b14e",
   "metadata": {},
   "source": [
    "There are potential pitfalls when dealing with NaN values, to which we will\n",
    "now turn our attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87bf45",
   "metadata": {},
   "source": [
    "As you see above, the Numpy `dtype` of the returned NaN value is `float64`.\n",
    "This tells us that the NaN value is a special and particular type of floating\n",
    "point value, in the same sense that Inf (infinity) or -Inf (negative\n",
    "infinity) are special floating point values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inf (np.inf) is another special floating point value.\n",
    "np.array(1) / np.array(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39c26a",
   "metadata": {},
   "source": [
    "Numpy uses this special NaN (`np.nan`) value to indicate that the value is\n",
    "*invalid*.  We will soon see that Pandas uses `np.nan` in a different and expanded meaning.  But more of that in a little while.\n",
    "\n",
    "The logic of NaNs as *invalid values* means that *any* operation with a NaN should return — a NaN — because any operation with an invalid value must itself be an invalid value.  This propagation can have some superficially unexpected consequences that can trap the unwary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A (potentially) unexpected False\n",
    "a_nan == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52be931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another strange result with the equality operator\n",
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ab1468",
   "metadata": {},
   "source": [
    "The last two cells above both return a `False` value because NaN value is\n",
    "treated as an invalid value.  For a NaN, a value is *invalid*, so\n",
    "comparing any value to a NaN is itself a NaN, even if the other value is\n",
    "a NaN.\n",
    "\n",
    "To ask the question *is this value a NaN*, use `np.isnan()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84150ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(a_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75542d4a",
   "metadata": {},
   "source": [
    "The same principles apply when we are dealing with NaN values in an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d15c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new array with NaN and non-NaN values\n",
    "arr = np.array([np.nan, np.nan, 1, 3])\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf7dea2",
   "metadata": {},
   "source": [
    "Again, if we want to find which of these values as NaNs, we might (early in our programming careers) try something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29474da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably not what you meant.\n",
    "arr == np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8712725e",
   "metadata": {},
   "source": [
    "This has failed to identify the NaN elements, because NaNs propagate, and therefore any operation with a NaN gives a NaN, and therefore the comparison `==` with a NaN value returns NaN.\n",
    "\n",
    "You may well want `np.isnan()` here; it does ask the question — which of these values are NaNs — returning True where the value is NaN, and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab155af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably what you did mean.\n",
    "np.isnan(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f303461c",
   "metadata": {},
   "source": [
    "Perhaps more obviously, any mathematical operation with NaN gives NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f6cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplying NaNs by something.\n",
    "arr * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fa9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding with NaNs\n",
    "arr + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802bfd97",
   "metadata": {},
   "source": [
    "OK, so the [TL;DR](https://en.wikipedia.org/wiki/TL;DR) here is that in Numpy\n",
    "NaNs signal an invalid operation has taken place.\n",
    "\n",
    "*NaNs propagate*;  any numerical operation a NaN will result in a NaN.\n",
    "\n",
    "Let's compare this to the way that Pandas uses NaNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb6f45",
   "metadata": {},
   "source": [
    "## NaNs in Pandas\n",
    "\n",
    "We have seen that NaN values in Numpy are values that indicate the result of\n",
    "invalid floating point operations.\n",
    "\n",
    "The function of NaN values in Pandas is somewhat different.\n",
    "\n",
    "NaN values in Pandas are *flags for missing data*. The NaN values themselves\n",
    "possess the same properties and pitfalls that we showed in the last section.\n",
    "However the *cause* of NaNs in Pandas is most often that *data was missing*\n",
    "rather than invalid numerical operations being performed on the data.\n",
    "\n",
    "We'll say more about what Pandas means by *missing* below.\n",
    "\n",
    "Let's explore these concepts further by importing a dataset. We will use the\n",
    "full version of the [Human Development\n",
    "Index](https://ourworldindata.org/grapher/children-per-woman-vs-human-development-index)\n",
    "dataset, which contains values for every year, rather than just the subset of\n",
    "data from the year 2000, which we have looked at on previous pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data as Data Frame.\n",
    "df = pd.read_csv(\"data/children-per-woman-vs-human-development-index.csv\")\n",
    "# Set the index to the country codes.\n",
    "df = df.set_index('Code')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535f717",
   "metadata": {},
   "source": [
    "It is immediately apparent that this dataset contains more NaNs than\n",
    "a retirement village.[^also-nans]\n",
    "\n",
    "[^also-nans]: We apologise to our readers outside the US or UK, but this was\n",
    "  a small pun, because \"nan\" is a fairly popular way to refer to your\n",
    "  grandmother.\n",
    "\n",
    "Look at the `Human Development Index` column (which we extract as a Series):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A column with lots of NaN values.\n",
    "df['Human Development Index']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b282992",
   "metadata": {},
   "source": [
    "Let's take a closer look at the value in the first row of this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a28e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a nan value\n",
    "df['Human Development Index'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb3c1a",
   "metadata": {},
   "source": [
    "Sure enough, it's a NaN. It also has the expected `float64` data type that we\n",
    "saw above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e31fcd",
   "metadata": {},
   "source": [
    "We can use `np.isnan()` to get a Boolean confirmation that we are in the\n",
    "presence of a standard NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the `np.isnan()` function\n",
    "np.isnan(df['Human Development Index'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ef34f",
   "metadata": {},
   "source": [
    "Alternatively, you could use Pandas' own `pd.isna()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f18570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the `np.isnan()` function\n",
    "pd.isna(df['Human Development Index'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9023739",
   "metadata": {},
   "source": [
    "::: note\n",
    "\n",
    "**Pandas NA**\n",
    "\n",
    "In fact `pd.isna()` doesn't just check for NaN values, because Pandas has some\n",
    "other, less common ways to indicate an element is missing.  You will see this\n",
    "hinted in the name `pd.isna()`, because Pandas thinks of missing values as\n",
    "`NA` values, where NA [seems to stand for Not-Applicable or\n",
    "Not-Available](https://stats.stackexchange.com/questions/72907/in-statistics-what-does-na-stand-for).\n",
    "See [Working with Missing\n",
    "Data](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html)\n",
    "for the full gory details.  The summary at this stage is:\n",
    "\n",
    "* For readability, and to allow for the use of other NA values in Pandas, we suggest you use `pd.isna()` to check for missing values.\n",
    "* That said, at the moment, Pandas nearly always indicates missing (NA) values with Numpy's `np.nan`.\n",
    "\n",
    ":::\n",
    "\n",
    "Missing data - fancifully referred to as *missingness* - is common in the vast\n",
    "majority of datasets encountered in the wild. *Missing data* means data that,\n",
    "for whatever reason, are not present for a particular row and column.\n",
    "\n",
    "Above we saw, for example, that the HDI value for Afghanistan, and 1950, is missing (not available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd681bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914aa9a2",
   "metadata": {},
   "source": [
    "That is probably because there were no relevant statistics, for Afghanistan,\n",
    "in 1950, with which to calculate the value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee2422",
   "metadata": {},
   "source": [
    "We will nearly always want to know *how much* of a given dataset is missing, as we will need to factor this in as a limitation of our data analysis.\n",
    "\n",
    "**Start of exercise**\n",
    "\n",
    "Why might we worry about missing values?  Why can't we just drop them and forget about them?  Let's load some [related data from the World Bank](data/gender_stats) with country statistics on various measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60525c1d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "gender_df = pd.read_csv('data/gender_stats.csv')\n",
    "gender_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57faf4b",
   "metadata": {},
   "source": [
    "Notice that there are various NaN values here.\n",
    "\n",
    "A) Do you think these indicate invalid floating point operations at some previous step, or do they indicate missing (Not Available) data?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d0e0e",
   "metadata": {},
   "source": [
    "**Write your answer here, replacing this text.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e7103",
   "metadata": {},
   "source": [
    "Here is a calculation of the mean Health Exp(enditure) per Cap(ita) (per person):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df['health_exp_per_cap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd00f51",
   "metadata": {},
   "source": [
    "Do you think this value is a reasonable estimate of actual worldwide health expenditure per person?   If not, why not?   Can you think of any way of improving this estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb09c9",
   "metadata": {},
   "source": [
    "**Write your answer here, replacing this text.**\n",
    "\n",
    "**End of exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35319da",
   "metadata": {},
   "source": [
    "**See the [corresponding page](/pandas_from_numpy/0_4_dealing_with_missing_data_in_pandas.html) for solution**\n",
    "\n",
    "Pandas supplies us some useful methods for checking missingness.\n",
    "\n",
    "For instance, we can use `.count()` to show us the number of non-NaN elements in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count non-NaN (not missing) elements in the Data Frame.\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e382e",
   "metadata": {},
   "source": [
    "A useful trick here is to divide the output of the `.count()` method by the\n",
    "`len()` of the Data Frame.  Remember [`len(df)` gives you the number of rows\n",
    "(number of observations)](len-df).  This provides a handy summary of the\n",
    "*proportion* of NaNs in each column of the Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f220191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the proportion of missing values, in each column.\n",
    "# The division operates elementwise, dividing all values above by the divisor.\n",
    "df.count() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672d2521",
   "metadata": {},
   "source": [
    "If we want to use brute force, we can use the `.dropna()` method to remove *any rows* which have a single NaN value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f810b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the NaN values\n",
    "df_no_NaN = df.dropna()\n",
    "df_no_NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd49b4",
   "metadata": {},
   "source": [
    "It turns out in this dataset, every row has at least one NaN value so dropping every row with a NaN has dropped *everything*...(we did say this method was brute force)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c0701",
   "metadata": {},
   "source": [
    "**By far the most important thing to know about missing data in Pandas** is that **by default NaN values will be *ignored* in numerical operations**.\n",
    "\n",
    "Let's look at the `Fertility Rate` column, which contains numerical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the column\n",
    "df['Fertility Rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f426005",
   "metadata": {},
   "source": [
    "Because we are dealing with just one column, we can safely use `.dropna()` without losing every row (because not every row of the *Series* contains a NaN value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the column\n",
    "df['Fertility Rate'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c552c",
   "metadata": {},
   "source": [
    "Let's compare computing a statistic (the mean) when we drop the NaN values from this Series versus when we leave them in.\n",
    "\n",
    "When we use the `.mean()` method on just this column, we get the following value:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53b95bf",
   "metadata": {},
   "source": [
    "Let's first select all the rows relating to (indexed as) Zimbabwe (`'ZWE'`), and the corresponding `'Fertility Rate'` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows with index value 'ZWE', 'Fertility Rate' column.\n",
    "zwe_fert = df.loc['ZWE', 'Fertility Rate']\n",
    "zwe_fert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1744f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a mean with NaN data included (NaNs will be ignored).\n",
    "zwe_fert.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dfb008",
   "metadata": {},
   "source": [
    "Using `.dropna()` on this column returns *exactly the same value* - because by default Pandas will ignore NaNs in numerical operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71629e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "zwe_no_nans = zwe_fert.dropna()\n",
    "zwe_no_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaNs gives the same mean \n",
    "zwe_no_nans.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca015731",
   "metadata": {},
   "source": [
    "So:\n",
    "\n",
    "* For Numpy, NaNs propagate, because they indicate an *invalid value*.\n",
    "* For Pandas, NaNs do not propagate, because they indicate a *missing value*.\n",
    "\n",
    "Put another way:\n",
    "\n",
    "* Numpy treats NaNs as *numerical* indicators of an invalid operation.\n",
    "* Pandas treats NaNs as *statistical* indicators of missing data.\n",
    "\n",
    "This fits with the package names; Numpy for *numerical Python*, Pandas for\n",
    "*Panel data* and therefore, statistics.\n",
    "\n",
    "This difference in NaN handling is a key and important difference between Numpy\n",
    "and Pandas statistical routines.  Numpy `mean`, `min`, `max` and `std` return\n",
    "NaN, by default, if there are any NaN values in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(zwe_fert.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c7ff8",
   "metadata": {},
   "source": [
    "In contrast, the matching routines in Pandas silently drop the NaN values before calculating `mean`, `min`, `max` and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zwe_fert.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c2b439",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "On this page we have seen how NaN values indicate different things in Numpy and\n",
    "Pandas.\n",
    "\n",
    "In Numpy, NaN values have a *numerical* meaning, and typically result from\n",
    "invalid computations, such as dividing zero by zero.\n",
    "\n",
    "In Pandas, NaN values have *statistical* meaning.  They are most commonly flags for\n",
    "missing data. By default, these NaN values will be ignored when you call\n",
    "Pandas' statistical methods for Series or Data Frames."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
